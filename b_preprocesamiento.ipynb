{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings ## funciones para imprimir y registrar advertencias.\n",
    "warnings.filterwarnings(\"ignore\") #suprimir cualquier advertencia que pueda ser generada por el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Librerias\n",
    "\n",
    "import pandas as pd ### para manejo de datos\n",
    "import a_funciones as funciones  ###archivo de funciones propias\n",
    "import sys ## saber ruta de la que carga paquetes\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ruta directorio que tiene paquetes\n",
    "\n",
    "sys.path\n",
    "sys.path.append('c:\\\\Users\\\\luisa\\\\OneDrive\\\\Desktop\\\\Analitica lll RH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lectura de datos \n",
    "\n",
    "df1 = pd.read_csv(\"https://raw.githubusercontent.com/andressj1/A-RH/main/Bases/employee_survey_data.csv\", sep=\",\")\n",
    "df2 = pd.read_csv(\"https://raw.githubusercontent.com/andressj1/A-RH/main/Bases/general_data.csv\", sep=\",\")\n",
    "df3 = pd.read_csv(\"https://raw.githubusercontent.com/andressj1/A-RH/main/Bases/manager_survey.csv\", sep=\",\")\n",
    "df4 = pd.read_csv(\"https://raw.githubusercontent.com/andressj1/A-RH/main/Bases/retirement_info.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento para la base1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8820 entries, 0 to 8819\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Unnamed: 0               8820 non-null   int64  \n",
      " 1   EmployeeID               8820 non-null   int64  \n",
      " 2   EnvironmentSatisfaction  8770 non-null   float64\n",
      " 3   JobSatisfaction          8780 non-null   float64\n",
      " 4   WorkLifeBalance          8744 non-null   float64\n",
      " 5   DateSurvey               8820 non-null   object \n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 413.6+ KB\n"
     ]
    }
   ],
   "source": [
    "### Visualizacion de datos \n",
    "\n",
    "df1.head(3)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminacion de columna que no aportaria en el modelo\n",
    "\n",
    "df1.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID                  0\n",
      "EnvironmentSatisfaction    50\n",
      "JobSatisfaction            40\n",
      "WorkLifeBalance            76\n",
      "DateSurvey                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Verificación de valores nulos\n",
    "\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    2700\n",
      "4.0    2668\n",
      "2.0    1712\n",
      "1.0    1690\n",
      "Name: EnvironmentSatisfaction, dtype: int64\n",
      "2.7236031927023947\n",
      "3.0\n",
      "-------------------------------\n",
      "4.0    2734\n",
      "3.0    2646\n",
      "1.0    1720\n",
      "2.0    1680\n",
      "Name: JobSatisfaction, dtype: int64\n",
      "2.728246013667426\n",
      "3.0\n",
      "-------------------------------\n",
      "3.0    5320\n",
      "2.0    2038\n",
      "4.0     908\n",
      "1.0     478\n",
      "Name: WorkLifeBalance, dtype: int64\n",
      "2.7614364135407135\n",
      "3.0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Media, moda, y mediana de las variables\n",
    "\n",
    "print(df1['EnvironmentSatisfaction'].value_counts())\n",
    "print(df1['EnvironmentSatisfaction'].mean())\n",
    "print(df1['EnvironmentSatisfaction'].median())\n",
    "print('-------------------------------')\n",
    "\n",
    "print(df1['JobSatisfaction'].value_counts())\n",
    "print(df1['JobSatisfaction'].mean())\n",
    "print(df1['JobSatisfaction'].median())\n",
    "print('-------------------------------')\n",
    "\n",
    "print(df1['WorkLifeBalance'].value_counts())\n",
    "print(df1['WorkLifeBalance'].mean())\n",
    "print(df1['WorkLifeBalance'].median())\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tratamiento de faltantes\n",
    "\n",
    "\"\"\"Los nulos de EnvironmentSatisfaction y JobSatisfaction se reemplazan por 3.0, porque;\n",
    " * Es su categoria mas alta\n",
    " * Su Media es aproximadamente 3\n",
    " * Su Mediana es 3 \n",
    " \"\"\"\n",
    "\n",
    "df1['EnvironmentSatisfaction'] = df1['EnvironmentSatisfaction'].fillna(3.0) \n",
    "df1['JobSatisfaction'] = df1['JobSatisfaction'].fillna(3.0)\n",
    "\n",
    "\"\"\"Los nulos de WorkLifeBalance se reemplazan por 3.0 porque es su mediana, y es el valor mas aproximado\n",
    "a la media\"\"\"\n",
    "\n",
    "df1['WorkLifeBalance'] = df1['WorkLifeBalance'].fillna(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cambio al tipo correcto de dato\n",
    "\n",
    "\"\"\" En este caso solo fue DateSurvey porque es una fecha, y estaba en formato \"object\" \"\"\" \n",
    "\n",
    "df1['DateSurvey'] = pd.to_datetime(df1['DateSurvey'], format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento para la base2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8820 entries, 0 to 8819\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Unnamed: 0               8820 non-null   int64  \n",
      " 1   Age                      8820 non-null   int64  \n",
      " 2   BusinessTravel           8820 non-null   object \n",
      " 3   Department               8820 non-null   object \n",
      " 4   DistanceFromHome         8820 non-null   int64  \n",
      " 5   Education                8820 non-null   int64  \n",
      " 6   EducationField           8820 non-null   object \n",
      " 7   EmployeeCount            8820 non-null   int64  \n",
      " 8   EmployeeID               8820 non-null   int64  \n",
      " 9   Gender                   8820 non-null   object \n",
      " 10  JobLevel                 8820 non-null   int64  \n",
      " 11  JobRole                  8820 non-null   object \n",
      " 12  MaritalStatus            8820 non-null   object \n",
      " 13  MonthlyIncome            8820 non-null   int64  \n",
      " 14  NumCompaniesWorked       8782 non-null   float64\n",
      " 15  Over18                   8820 non-null   object \n",
      " 16  PercentSalaryHike        8820 non-null   int64  \n",
      " 17  StandardHours            8820 non-null   int64  \n",
      " 18  StockOptionLevel         8820 non-null   int64  \n",
      " 19  TotalWorkingYears        8802 non-null   float64\n",
      " 20  TrainingTimesLastYear    8820 non-null   int64  \n",
      " 21  YearsAtCompany           8820 non-null   int64  \n",
      " 22  YearsSinceLastPromotion  8820 non-null   int64  \n",
      " 23  YearsWithCurrManager     8820 non-null   int64  \n",
      " 24  InfoDate                 8820 non-null   object \n",
      "dtypes: float64(2), int64(15), object(8)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "### Visualizacion de datos \n",
    "\n",
    "df2.head(3)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables con un único valor:  Index(['EmployeeCount', 'Over18', 'StandardHours'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### Obtener la cantidad de valores únicos en cada columna \n",
    "\n",
    "\"\"\"Este codigo solo se aplico a esta base, debido a la gran cantidad de variables\"\"\"\n",
    "\n",
    "nunique_values = df2.nunique()\n",
    "single_value_columns = nunique_values[nunique_values == 1].index\n",
    "\n",
    "print(\"Variables con un único valor: \", single_value_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminacion de variables\n",
    "\n",
    "\"\"\"Las variables que solo tienen una categoria no nos dicen nada, por ende se las elimina. \n",
    "Tambien se elimina una variable Unnamed: 0; que es una variable innecesaria que se agrego cuando \n",
    "se cargo el modelo\"\"\"\n",
    "\n",
    "columns_to_drop = ['EmployeeCount', 'Over18', 'StandardHours', 'Unnamed: 0']\n",
    "df2 = df2.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                         0\n",
      "BusinessTravel              0\n",
      "Department                  0\n",
      "DistanceFromHome            0\n",
      "Education                   0\n",
      "EducationField              0\n",
      "EmployeeID                  0\n",
      "Gender                      0\n",
      "JobLevel                    0\n",
      "JobRole                     0\n",
      "MaritalStatus               0\n",
      "MonthlyIncome               0\n",
      "NumCompaniesWorked         38\n",
      "PercentSalaryHike           0\n",
      "StockOptionLevel            0\n",
      "TotalWorkingYears          18\n",
      "TrainingTimesLastYear       0\n",
      "YearsAtCompany              0\n",
      "YearsSinceLastPromotion     0\n",
      "YearsWithCurrManager        0\n",
      "InfoDate                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Verificación de valores nulos\n",
    "\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    3116\n",
      "0.0    1172\n",
      "3.0     948\n",
      "2.0     876\n",
      "4.0     830\n",
      "7.0     444\n",
      "6.0     416\n",
      "5.0     374\n",
      "9.0     312\n",
      "8.0     294\n",
      "Name: NumCompaniesWorked, dtype: int64\n",
      "2.6948303347756775\n",
      "2.0\n",
      "-------------------------------\n",
      "10.0    1210\n",
      "6.0      750\n",
      "8.0      614\n",
      "9.0      574\n",
      "5.0      528\n",
      "7.0      486\n",
      "1.0      484\n",
      "4.0      378\n",
      "12.0     288\n",
      "3.0      252\n",
      "15.0     240\n",
      "16.0     222\n",
      "13.0     216\n",
      "11.0     212\n",
      "21.0     204\n",
      "17.0     198\n",
      "14.0     186\n",
      "2.0      186\n",
      "20.0     178\n",
      "18.0     162\n",
      "23.0     132\n",
      "19.0     132\n",
      "22.0     124\n",
      "24.0     108\n",
      "25.0      84\n",
      "26.0      84\n",
      "28.0      84\n",
      "0.0       66\n",
      "29.0      60\n",
      "31.0      54\n",
      "32.0      54\n",
      "27.0      42\n",
      "30.0      42\n",
      "33.0      42\n",
      "36.0      36\n",
      "34.0      30\n",
      "37.0      24\n",
      "35.0      18\n",
      "40.0      12\n",
      "38.0       6\n",
      "Name: TotalWorkingYears, dtype: int64\n",
      "11.279936378095888\n",
      "10.0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Media, moda, y mediana\n",
    "\n",
    "print(df2['NumCompaniesWorked'].value_counts())\n",
    "print(df2['NumCompaniesWorked'].mean())\n",
    "print(df2['NumCompaniesWorked'].median())\n",
    "print('-------------------------------')\n",
    "\n",
    "print(df2['TotalWorkingYears'].value_counts())\n",
    "print(df2['TotalWorkingYears'].mean())\n",
    "print(df2['TotalWorkingYears'].median())\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tratamiento de nulos \n",
    "\n",
    "\"\"\"La variable NumCompaniesWorked se decidio reemplazar por 1, porque, es su categoria mas alta por mucho, y su\n",
    "siguiente categoria mas alta es 0.\n",
    "La variable TotalWorkingYears se decidio reemplazar por 10, porque, es su categoria mas alta y es su mediana\"\"\"\n",
    "\n",
    "df2['NumCompaniesWorked'] = df2['NumCompaniesWorked'].fillna(1.0)\n",
    "df2['TotalWorkingYears'] = df2['TotalWorkingYears'].fillna(10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cambio al tipo correcto de dato \n",
    "\n",
    "\"\"\" En este caso solo fue InfoDate porque es una fecha, y estaba en formato \"object\" \"\"\" \n",
    "df2['InfoDate'] = pd.to_datetime(df2['InfoDate'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento para la base3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8820 entries, 0 to 8819\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         8820 non-null   int64 \n",
      " 1   EmployeeID         8820 non-null   int64 \n",
      " 2   JobInvolvement     8820 non-null   int64 \n",
      " 3   PerformanceRating  8820 non-null   int64 \n",
      " 4   SurveyDate         8820 non-null   object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 344.7+ KB\n"
     ]
    }
   ],
   "source": [
    "### Visualizacion de datos\n",
    " \n",
    "df3.head(3)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Eliminacion de variables \n",
    "\n",
    "df3.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID           0\n",
      "JobInvolvement       0\n",
      "PerformanceRating    0\n",
      "SurveyDate           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Verificación de valores nulos\n",
    "\n",
    "\"\"\"En este caso no fue necesario tratar nulos\"\"\"\n",
    "print(df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cambio al tipo correcto de dato\n",
    "\n",
    "\"\"\" En este caso solo fue SurveyDate porque es una fecha, y estaba en formato \"object\" \"\"\" \n",
    "df3['SurveyDate'] = pd.to_datetime(df3['SurveyDate'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento para la base4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 711 entries, 0 to 710\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0.1       711 non-null    int64 \n",
      " 1   Unnamed: 0         711 non-null    int64 \n",
      " 2   EmployeeID         711 non-null    int64 \n",
      " 3   Attrition          711 non-null    object\n",
      " 4   retirementDate     711 non-null    object\n",
      " 5   retirementType     711 non-null    object\n",
      " 6   resignationReason  641 non-null    object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 39.0+ KB\n"
     ]
    }
   ],
   "source": [
    "### Visualizacion de datos \n",
    "\n",
    "df4.head(3)\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminacion de variables\n",
    "\n",
    "df4.drop([\"Unnamed: 0.1\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0            0\n",
      "EmployeeID            0\n",
      "Attrition             0\n",
      "retirementDate        0\n",
      "retirementType        0\n",
      "resignationReason    70\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Verificación de valores nulos\n",
    "\n",
    "print(df4.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others    323\n",
      "Salary    189\n",
      "Stress    129\n",
      "Name: resignationReason, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Contar el total de datos por categoria\n",
    "\n",
    "print(df4['resignationReason'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tratamiento de nulos \n",
    "\n",
    "\"\"\"Se crea la categoria desconocido porque no sabemos si sigue vigente en la empresa, o, si viceversa; el\n",
    "motivo. Tambien al ser una cantidad significativa de nulos probablemte se elimine\"\"\"\n",
    "df4['resignationReason'] = df4['resignationReason'].fillna(\"desconocido\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cambio al tipo correcto de dato\n",
    "\n",
    "\"\"\" En este caso solo fue retirementDate porque es una fecha, y estaba en formato \"object\" \"\"\" \n",
    "df4['retirementDate'] = pd.to_datetime(df4['retirementDate'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Union de bases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Union de bases\n",
    "\n",
    "\"\"\"Separar las bases en dos años; 2015 y 2016\n",
    "1. Se selecciona todas las filas, ya sea 2015 o 2016 \n",
    "2. Se crea la variable año, y se extrae solo el año\n",
    "3. Se borra la variable\"\"\"\n",
    "\n",
    "### Base 1\n",
    "\n",
    "# Crear tabla empleados 2015\n",
    "employe = df1[df1['DateSurvey'].dt.year == 2015]\n",
    "employe['año'] = employe['DateSurvey'].dt.strftime('%Y')\n",
    "employe.drop([\"DateSurvey\"], axis=1, inplace=True)\n",
    "\n",
    "# Crear tabla empleados 2016\n",
    "employe1 = df1[df1['DateSurvey'].dt.year == 2016]\n",
    "employe1['año'] = employe1['DateSurvey'].dt.strftime('%Y')\n",
    "employe1.drop([\"DateSurvey\"], axis=1, inplace=True)\n",
    "\n",
    "### Base 2\n",
    "\n",
    "#2015\n",
    "general = df2[df2['InfoDate'].dt.year == 2015]\n",
    "general['año'] = general['InfoDate'].dt.strftime('%Y')\n",
    "general.drop([\"InfoDate\"], axis=1, inplace=True)\n",
    "\n",
    "#2016\n",
    "general1 = df2[df2['InfoDate'].dt.year == 2016]\n",
    "general1['año'] = general1['InfoDate'].dt.strftime('%Y')\n",
    "general1.drop([\"InfoDate\"], axis=1, inplace=True)\n",
    "\n",
    "### Base3 \n",
    "\n",
    "#2015\n",
    "manager = df3[df3['SurveyDate'].dt.year == 2015]\n",
    "manager['año'] = manager['SurveyDate'].dt.strftime('%Y')\n",
    "manager.drop([\"SurveyDate\"], axis=1, inplace=True)\n",
    "\n",
    "#2016\n",
    "manager1 = df3[df3['SurveyDate'].dt.year == 2016]\n",
    "manager1['año'] = manager1['SurveyDate'].dt.strftime('%Y')\n",
    "manager1.drop([\"SurveyDate\"], axis=1, inplace=True)\n",
    "\n",
    "### Base4 \n",
    "\n",
    "#2015\n",
    "retirement = df4[df4['retirementDate'].dt.year == 2015]\n",
    "retirement['año'] = retirement['retirementDate'].dt.strftime('%Y')\n",
    "retirement.drop([\"retirementDate\"], axis=1, inplace=True)\n",
    "\n",
    "#2016\n",
    "retirement1 = df4[df4['retirementDate'].dt.year == 2016]\n",
    "retirement1['año'] = retirement1['retirementDate'].dt.strftime('%Y')\n",
    "retirement1.drop([\"retirementDate\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Union de bases\n",
    "\n",
    "\"\"\"Se unen usando la columna 'EmployeeID' como clave\"\"\"\n",
    "\n",
    "df2015 = employe.merge(general, on='EmployeeID', how='inner')\\\n",
    "                        .merge(manager, on='EmployeeID', how='inner')\\\n",
    "                        .merge(retirement1, on='EmployeeID', how='left')\n",
    "                        \n",
    "\n",
    "df2016 = employe.merge(general1, on='EmployeeID', how='inner')\\\n",
    "                        .merge(manager1, on='EmployeeID', how='inner')\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exportacion de bases \n",
    "df2015.to_csv(r'C:\\Users\\luisa\\OneDrive\\Desktop\\Analitica lll RH\\Bases\\base2015.csv', index=False)\n",
    "df2016.to_csv(r'C:\\Users\\luisa\\OneDrive\\Desktop\\Analitica lll RH\\Bases\\base2016.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
